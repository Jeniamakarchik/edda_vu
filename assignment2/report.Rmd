---
title: "Assignment 2"
author: "Alexia Salomons, Nathan Maxwell Jones, Yauheniya Makarevich, group 71"
date: "15 March 2023"
output: pdf_document
fontsize: 11pt
highlight: tango
---

```{r setup, include = FALSE}
# set up global R options
options(digits = 3)

# set up knitr global chunk options
knitr::opts_chunk$set(fig.height = 3)
```


## Exercise 1

```{r, include=FALSE}
tree_df <- as.data.frame(read.table("data/treeVolume.txt", header=TRUE))
head(tree_df)
```

**a)** 
To investigate whether tree type influences total wood volume, we can perform a one-way ANOVA.

```{r}
tree_df$type <- as.factor(tree_df$type)
tree_type_lm <- lm(volume~type, data=tree_df)
anova(tree_type_lm)
```

With $p > 0.05$, we can conclude that *type* does not have a significant effect on *volume*. Because the factor *type* has two levels, we can apply a two sample t-test.

```{r}
mask <- tree_df$type == "beech"
t.test(tree_df$volume[mask], tree_df$volume[!mask])
```
This supports the result from the ANOVA test. The estimated volume is 30.2 for Beech trees and 35.2 for Oak trees.

**b)** 

To investigate this claim, we create two models, each including all three explanatory variables (*type*, *diameter* and *height*). In the first model, we also include the pairwise interaction between *type* and *diameter*.

```{r}
tree_type_d_lm <- lm(volume~height+type*diameter, data=tree_df)
anova(tree_type_d_lm)
```

In the second model, we include the pairwise interaction between *type* and *height*.

```{r}
tree_type_h_lm <- lm(volume~diameter+type*height, data=tree_df)
anova(tree_type_h_lm)
```

We see that both pairwise interactions are not significant. Therefore, we can conclude that both *height* and *diameter* have the same influence on *volume* regardless of *type*.

**c)** 

In (b), we saw that the interactions of *height* and *diameter* with *type* were not significant, and so we will investigate a purely additive model (assuming no interactions).

```{r}
tree_add_all_lm <- lm(volume~diameter+height+type, data=tree_df)
drop1(tree_add_all_lm, test= "F")
```

We see that the effect of *type* is not significant in the additive model. Therefore we will investigate an additive model that excludes *type*.

```{r}
tree_add_dh_lm <- lm(volume~diameter+height, data=tree_df)
anova(tree_add_dh_lm)
```
```{r}
summary(tree_add_dh_lm)
```

This model has a high R-squared value while using fewer variables, all of which are significant. Since simpler models are generally preferred, this is our model of choice to make predictions. As a final test, we need to check this model's assumptions to ensure that the conclusions we draw from it are valid:

```{r, echo=FALSE}
par(mfrow=c(1, 2))
qqnorm(residuals(tree_add_dh_lm))
plot(fitted(tree_add_dh_lm), residuals(tree_add_dh_lm))
```
While these plots are not perfect, we believe the model assumptions to be valid. 

Therefore, the effects of *type*, *diameter* and *height* can be summarized as follows:

* The tree *type* does not affect volume significantly.
* Looking at the coefficients, we see that increasing both height and diameter result in an increase in volume, with diameter having a bigger impact (with a gradient of 4.63 compared to *height's* 0.43). This makes sense given that we know volume is proportional to the square of the diameter.

To predict the volume for a tree with the overall average diameter and height, we can use the following linear regression model:

$$volume = -64.37 + 4.63 * diameter + 0.43 * height$$
```{r}
mean_d <- mean(tree_df$diameter)
mean_h <- mean(tree_df$height)
means <-  data.frame(diameter=c(mean_d), height=c(mean_h))

predict(tree_add_dh_lm, means, interval = "confidence")
```
Therefore we expect the volume for such a tree to be 32.6.

**d)** 
Assuming that a tree is roughly cylindrical, we expect that *volume* would be proportional to the *height* multiplied by the square of *diameter*. We perform this transformation and add it as a new column in the data frame. We could apply the true transformation, $V = h \times \pi (d/2)^2$, but this would just add unnecessary constants which would already be captured in the regression coefficients. We also will not include *type* because it was not significant.


```{r}
tree_df$math_volume <- tree_df$height * tree_df$diameter^2
math_volume_lm <- lm(volume~math_volume, data=tree_df)
anova(math_volume_lm)
```

```{r}
summary(math_volume_lm)
```

We see that this transformation does indeed produce an explanatory value with a significant effect. We also see that the R-squared (0.975) and adjusted R-squared (0.974) values are higher than that of the model chosen in (c) (tree_add_dh_lm), indicating that it better explains the data. Finally, we check the assumptions of this model.

```{r, echo=FALSE}
par(mfrow=c(1,2))

qqnorm(residuals(math_volume_lm))
plot(fitted(math_volume_lm), residuals(math_volume_lm))
```

These plots are acceptable, meaning we can accept the model assumptions.

## Exercise 2

```{r, include=FALSE}
# Read data
crime_df <- as.data.frame(read.table("data/expensescrime.txt", header=TRUE))
head(crime_df)

response <- "expend"
exp_vars <- c("bad", "crime", "lawyers", "employ", "pop")
```

**a)** 

To investigate the interactions between all the variables of interest, we can plot the pairwise scatter plots for all their combinations:

```{r, echo=FALSE, fig.height=5}
pairs(crime_df[, c(response, exp_vars)])
```

We see that *expend*, our response variable, appears to have a positive correlation with all the explanatory variables except for *crime*. There appear to be several outliers at the high end of the data which could skew the model. We can also see that collinearity exists between the explanatory variables *bad*, *lawyers*, *employ* and *pop*. This is a problem since the redundant information will make the regression coefficients difficult to estimate. 

We can use Cook's distance to find the influence points (a distance greater than 1 indicates an outlier)

```{r}
crime_lm <- lm(expend~bad+crime+lawyers+employ+pop, data=crime_df)
cooks.distance(crime_lm)[cooks.distance(crime_lm) > 1]
```
```{r, include=FALSE}
plot(cooks.distance(crime_lm), type='b', ylab="Cook's distance", main = "Cook's distance for expensecrime.txt")
```

We can see that indices of 5, 8, 35 and 44 are outliers, which we can remove:

```{r}
crime_df_upd <- crime_df[-c(5,8,35,44),]
```

To further investigate collinearity, we can examine the correlations between all the explanatory variables, which confirms strong correlations between *bad*, *lawyers*, *employ* and *pop*.

```{r}
round(cor(crime_df[, c(exp_vars)]), 2)
```

We can also use the VIF to see which variables are collinear (VIF > 5 is cause for concern).

```{r, include=FALSE}
library(car)
```
```{r}
vif(lm(expend~bad+crime+lawyers+employ+pop, data=crime_df))
```

This further confirms that collinearity exists for the variables *bad*, *lawyers*, *employ* and *pop*.

**From this point on, we will proceed *without* the influence points.**

**b)** 

```{r, include=FALSE}
print("Step 1")

print("bad")
summary(lm(expend~bad, data=crime_df_upd))

print("crime")
summary(lm(expend~crime, data=crime_df_upd))

print("lawyers")
summary(lm(expend~lawyers, data=crime_df_upd))

print("employ")
summary(lm(expend~employ, data=crime_df_upd)) # YES

print("pop")
summary(lm(expend~pop, data=crime_df_upd)) 
```

```{r, include=FALSE}
print("Step 2")

print("bad")
summary(lm(expend~employ+bad, data=crime_df_upd))

print("crime")
summary(lm(expend~employ+crime, data=crime_df_upd)) # YES

print("lawyers")
summary(lm(expend~employ+lawyers, data=crime_df_upd))

print("pop")
summary(lm(expend~employ+pop, data=crime_df_upd))
```

```{r, include=FALSE}
print("Step 3")

print("bad")
summary(lm(expend~employ+crime+bad, data=crime_df_upd))

print("lawyers")
summary(lm(expend~employ+crime+lawyers, data=crime_df_upd))

print("pop")
summary(lm(expend~employ+crime+pop, data=crime_df_upd)) # YES
```

```{r, include=FALSE}
print("Step 4")

print("bad")
summary(lm(expend~employ+crime+pop+bad, data=crime_df_upd))

print("lawyers")
summary(lm(expend~employ+crime+pop+lawyers, data=crime_df_upd))

# None significant!
```

The step-up process was carried out. The variables added in order were *employ*, *crime* and *pop*, after which no further added variables had significant p-values. Hence the final model is as follows:

```{r}
step_up_lm <- lm(expend~employ+crime+pop, data=crime_df_upd)
summary(step_up_lm)
```

Final model: expend = -247 + 0.0209\*employ + 0.0543\*crime + 0.0714\*pop $\pm$ error, with $R^2 = 0.974$. Using VIF we can 

```{r}
vif(step_up_lm)
```


We see that the step-up method naturally removes collinearity and produced a better model than was arrived upon using VIF in (a), which had an R-squared value of 0.957.

Finally, we check the model assumptions, which can be accepted based on the following plots:

```{r, echo=FALSE}
par(mfrow=c(1,2))

qqnorm(residuals(step_up_lm))
plot(fitted(step_up_lm), residuals(step_up_lm))
```

**c)** 

Using the step-up model found in (b), the 95% prediction interval for *expend* is given by:
```{r}
new_data <- data.frame(bad=50, crime=5000, lawyers=5000, employ=5000, pop=5000)
predict(step_up_lm, new_data, interval="prediction", level=0.95)
```

We cannot improve this interval since we have already removed the influence points from the data.

```{r, include=FALSE}
predict(step_up_lm, new_data, interval="confidence", level=0.95)
```

**d)** 

We can apply the LASSO method as follows:

```{r, include=FALSE}
# install.packages("glmnet", repos = "https://cran.us.r-project.org")
library(glmnet)
```

```{r}
x <- as.matrix(crime_df_upd[, exp_vars])
y <- as.matrix(crime_df_upd[, c(response)])

# train-test splitting
train <- (sample(1:nrow(x), 0.67*nrow(x))) # train by using 2/3 of the data
x.train <- x[train,]; y.train <- y[train]
x.test <- x[-train,]; y.test <- y[-train]

# fitting the model
lasso.mod <- glmnet(x.train, y.train, alpha=1)
cv.lasso <- cv.glmnet(x.train,y.train,alpha=1,type.measure='mse')
```

```{r}
plot(lasso.mod, label=T, xvar="lambda")  # have a look at the lasso path
```

```{r}
plot(cv.lasso) # the best lambda by cross-validation
```

```{r}
(lambda.1se <- cv.lasso$lambda.1se)
```

```{r}
# https://glmnet.stanford.edu/articles/glmnet.html#assessing-models-on-test-data-1
assess.glmnet(lasso.mod, newx = x.test, newy = y.test, s=cv.lasso$lambda.1se)
```

Looking at lambda 1se
```{r}
coef(lasso.mod, s=cv.lasso$lambda.1se) # beta’s for lambda.1se
y.pred <- predict(lasso.mod, s=lambda.1se, newx=x.test) # predict for test
mse.lasso <- mean((y.test - y.pred)^2); mse.lasso # mse for the predicted test rows
```

To compare this to the step-up model in (b), we can find the MSE for this model.

```{r}
new_data <- data.frame(x.test)
y.pred <- predict(step_up_lm, new_data, interval="confidence", level=0.95)
mse.step_up <- mean((y.test - y.pred)^2); mse.step_up # mse for the predicted test rows
```

We see that the step-up model outperforms the LASSO model, producing a smaller MSE. This could be because LASSO is better suited to situations with many more explanatory variables.

## Exercise 3

```{r, include=FALSE}
# Read data
titanic_df <- as.data.frame(read.table("data/titanic.txt", header=TRUE))
head(titanic_df)
```

**a)** 

```{r}
titanic_df$PClass <- as.factor(titanic_df$PClass)
titanic_df$Sex <- as.factor(titanic_df$Sex)
summary(titanic_df)
```

```{r}
tot_comb <- xtabs(~PClass+Sex, data=titanic_df)
tot_comb
```
```{r}
tot_comb.surv <- xtabs(Survived~PClass+Sex, data=titanic_df)
round(tot_comb.surv/tot_comb, 2)
```

```{r}
par(mfrow=c(1, 2))
hist(titanic_df$Age)
hist(titanic_df$Age[titanic_df$Survived == 1], ylim =c(0, 140))
```


```{r}
boxplot(Age ~ Sex + PClass, data=titanic_df, col = c("#FFE0B2", "#F57C00")) 
```

Removing rows with missing ages:
```{r}
titanic_df_upd <- na.omit(titanic_df)
```

Fitting the logistic regression model.

```{r}
titanic_df_upd$PClass <- as.factor(titanic_df_upd$PClass)
titanic_df_upd$Sex <- as.factor(titanic_df_upd$Sex)
base_lm <- glm(Survived ~ Age+PClass+Sex, data = titanic_df_upd, family = binomial)
```

```{r}
drop1(base_lm, test = "Chisq")
```
```{r}
summary(base_lm)
```


```{r}
exp(coef(base_lm))
```

TODO: add discussion of odds from the paper

**b)** 

```{r}
anova(glm(Survived ~ Age*PClass, data = titanic_df_upd, family = binomial), test="Chisq")
```

```{r}
anova(glm(Survived ~ Age*Sex, data = titanic_df_upd, family = binomial), test="Chisq")
```
Therefore we decided to keep following model as Age:Sex interaction is significant. PClass was significant by itself, so we include it in the final model.

<<<<< INVESTIGATE VARIABLES USING anova(smaller model, bigger model) >>>>>>
```{r}
final_lm <- glm(Survived ~ PClass+Age*Sex, data = titanic_df_upd, family = binomial)
summary(final_lm, test="Chisq")
```

<<<<< THIS MODEL MAY CHANGE >>>>>
```{r}
newdata <- data.frame(Age=c(55, 55, 55, 55, 55, 55), PClass=c("1st", "1st", "2nd", "2nd", "3rd", "3rd"), Sex=c("female", "male", "female", "male", "female", "male"))
predict(final_lm, newdata, type="response")
```

For "female" all the probs > 0.5 and for the "male" probs are < 0.5.

**c)** 

We can predict the survival status of the individuals by looking at the fitted values produced by the model, which gives the probability of survival. We can then set a threshold of 0.5. We can predict that those with a probability lower than this did not survive, and those with a probability higher than this did survive. To measure the quality of this prediction method, we can use tools such as a confusion matrix and log likelihood as quality measures.

**d)** 

**Survived vs SEX**

For 2x2 tables we can obtain exact p-value using the Fisher test.

```{r}
fisher.test(x=titanic_df_upd$Survived, y=titanic_df_upd$Sex)
```
Therefore *Sex* and *Survived* are not independent.

```{r}
chisq.test(x=titanic_df_upd$Survived, y=titanic_df_upd$PClass)
```
Therefore *PClass* and *Survived* are not independent.

**e)** 

Logistic 

A - Also tells you *how* and *how much* the response depends on the variable
D - https://careerfoundry.com/en/blog/data-analytics/what-is-logistic-regression/

vs 

Contingency 

A - since only testing for effect, maybe more reliable outcome?
D - Only tells you whether dependence exists... not the nature of it

vs 

Fisher

A - exact p-value
D - only works for 2x2

contingency table tells us only about the presence of effect and doesn't provide some quantitative characteristics

## Exercise 4

```{r, include=FALSE}
# Read data
coups_df <- as.data.frame(read.table("data/coups.txt", header=TRUE))
head(coups_df)
```


```{r}
coups_df$pollib <- as.factor(coups_df$pollib)
```


**a)** 
```{r}
poison_glm <- glm(miltcoup ~ oligarchy + parties + pctvote + popn + size + numelec + numregim + pollib, data = coups_df, family = poisson)
drop1(poison_glm, test= "Chisq")
summary(poison_glm)
```


Through Poisson regression, and its summary, we can find that the variables that are significant in predicting number of successful military coups are: *oligarchy*, *pollib*, and *parties*.

**b)** 

```{r, include=FALSE}
summary(glm(miltcoup ~ oligarchy + parties + pctvote + popn + size + numelec + pollib, data = coups_df, family = poisson), test="Chisq")
```

```{r, include=FALSE}
summary(glm(miltcoup ~ oligarchy + parties + pctvote + popn + size + pollib, data = coups_df, family = poisson), test="Chisq")
```

```{r, include=FALSE}
summary(glm(miltcoup ~ oligarchy + parties + pctvote + popn + pollib, data = coups_df), test="Chisq")
```

```{r, include=FALSE}
summary(glm(miltcoup ~ oligarchy + parties + pctvote + pollib, data = coups_df), test="Chisq")
```

```{r, include=FALSE}
final_plm <- glm(miltcoup ~ oligarchy + parties + pollib, data = coups_df, family = poisson)
summary(final_plm, test="Chisq")
```

The step down method was applied, removing the variables: *numelec*, *size*, *popn*, and *pctvote*, respectively. After which, all remaining variables were significant, resulting in the model:
```{r}
final_plm <- glm(miltcoup ~ oligarchy + parties + pollib, data = coups_df, family = poisson)
summary(final_plm, test="Chisq")
```
In comparison with a) all the same variables are significant.

**c)** 

```{r}
coups_df$pollib <- as.factor(coups_df$pollib)
```

```{r}
mean(coups_df$oligarchy); mean(coups_df$parties)
```


```{r}
newdata <- data.frame(pollib=c("0", "1", "2"), oligarchy=c(5.22, 5.22, 5.22), parties=c(17.1, 17.1, 17.1))
predict(final_plm, newdata, type="response")
```

Our model predicts that there will be roughly 3 successful coups for pollib=0, roughly 2 successful coups for pollib=1 and 1 successful coup for pollib=2.
