---
title: "Assignment 2"
author: "Alexia Salomons, Nathan Maxwell Jones, Yauheniya Makarevich, group 71"
date: "15 March 2023"
output: pdf_document
fontsize: 11pt
highlight: tango
---

```{r setup, include = FALSE}
# set up global R options
options(digits = 3)

# set up knitr global chunk options
knitr::opts_chunk$set(fig.height = 3)
```


## Exercise 1

```{r, include=FALSE}
tree_df <- as.data.frame(read.table("data/treeVolume.txt", header=TRUE))
head(tree_df)
```

**a)** 
To investigate whether tree type influences total wood volume, we can perform a one-way ANOVA.
```{r}
tree_df$type <- as.factor(tree_df$type)
tree_type_lm <- lm(volume~type, data=tree_df)
anova(tree_type_lm)
```

With $p > 0.05$, we can conclude that *type* does not have a significant effect on *volume*. Because the factor *type* has two levels, we can apply a two sample t-test.

```{r}
mask <- tree_df$type == "beech"
t.test(tree_df$volume[mask], tree_df$volume[!mask])
```
This supports the result from the ANOVA test. The estimated volume is 30.2 for Beech trees and 35.2 for Oak trees.

**b)** 
To investigate this claim, we create two models, each including all three explanatory variables (*type*, *diameter* and *height*). In the first model, we also include the pairwise interaction between *type* and *diameter*.
```{r}
tree_type_d_lm <- lm(volume~height+type*diameter, data=tree_df)
anova(tree_type_d_lm)
```

```{r}
summary(tree_type_d_lm)
```


```{r}
tree_type_h_lm <- lm(volume~diameter+type*height, data=tree_df)
anova(tree_type_h_lm)
```

```{r}
summary(tree_type_h_lm)
```

We see that both pairwise interactions are not significant. Therefore, we can conclude that both *height* and *diameter* have the same influence on *volume* regardless of *type*. Both models suggest that all three explanatory variables have a significant effect individually.

**c)** 

In (b), we saw that the interactions of *height* and *diameter* with *type* were not significant, and so we will investigate a purely additive model (assuming no interactions).

```{r}
tree_add_all_lm <- lm(volume~diameter+height+type, data=tree_df)
anova(tree_add_all_lm)
```
```{r}
summary(tree_add_all_lm)
```

We see that the effect of *type* is not significant in the additive model. Therefore we will investigate an additive model that excludes *type*.

```{r}
tree_add_dh_lm <- lm(volume~diameter+height, data=tree_df)
anova(tree_add_dh_lm)
```
```{r}
summary(tree_add_dh_lm)
```
This model has a high R-squared value while using fewer variables, all of which are significant. Since simpler models are generally preferred, this is our model of choice to make predictions. As a final test, we need to check this model's assumptions to ensure that the conclusions we draw from it are valid:

```{r, echo=FALSE}
par(mfrow=c(1, 2))
qqnorm(residuals(tree_add_dh_lm))
plot(fitted(tree_add_dh_lm), residuals(tree_add_dh_lm))
```
While these plots are not perfect, we believe the model assumptions to be valid. 

Therefore, the effects of *type*, *diameter* and *height* can be summarized as follows:

* The tree *type* does not affect volume significantly.
* Looking at the coefficients, we see that increasing both height and diameter result in an increase in volume, with diameter having a bigger impact (with a gradient of 4.63 compared to *height's* 0.43). This makes sense given that we know volume is proportional to the square of the diameter.

To predict the volume for a tree with the overall average diameter and height, we can use the following linear regression model:

$$volume = -64.37 + 4.63 * diameter + 0.43 * height$$
```{r}
mean_d <- mean(tree_df$diameter)
mean_h <- mean(tree_df$height)
means <-  data.frame(diameter=c(mean_d), height=c(mean_h))

predict(tree_add_dh_lm, means, interval = "confidence")
```
Therefore we expect the volume for such a tree to be 32.6.

**d)** 
Assuming that a tree is roughly cylindrical, we expect that *volume* would be proportional to the *height* multiplied by the square of *diameter*. We perform this transformation and add it as a new column in the data frame. We could apply the true transformation, $V = h \times \pi (d/2)^2$, but this would just add unnecessary constants which would already be captured in the regression coefficients. We also will not include *type* because it was not significant.


```{r}
tree_df$math_volume <- tree_df$height * tree_df$diameter^2
math_volume_lm <- lm(volume~math_volume, data=tree_df)
anova(math_volume_lm)
```

```{r}
summary(math_volume_lm)
```

We see that this transformation does indeed produce an explanatory value with a significant effect. We also see that the R-squared (0.975) and adjusted R-squared (0.974) values are higher than that of the model chosen in (c) (tree_add_dh_lm), indicating that it better explains the data. Finally, we check the assumptions of this model.

```{r, echo=FALSE}
par(mfrow=c(1,2))

qqnorm(residuals(math_volume_lm))
plot(fitted(math_volume_lm), residuals(math_volume_lm))
```

These plots are acceptable, meaning we can accept the model assumptions.

## Exercise 2

```{r, include=FALSE}
# Read data
crime_df <- as.data.frame(read.table("data/expensescrime.txt", header=TRUE))
head(crime_df)

response <- "expend"
exp_vars <- c("bad", "crime", "lawyers", "employ", "pop")
```

**a)** 

To investigate the interactions between all the variables of interest, we can plot the pairwise scatter plots for all their combinations:

```{r, echo=FALSE, fig.height=5}
pairs(crime_df[, c(response, exp_vars)])
```

We see that *expend*, our response variable, appears to have a positive correlation with all the explanatory variables except for *crime*. There appear to be several outliers at the high end of the data which could skew the model. We can also see that collinearity exists between the explanatory variables *bad*, *lawyers*, *employ* and *pop*. This is a problem since the redundant information will make the regression coefficients difficult to estimate. 

We can use Cook's distance to find the influence points (a distance greater than 1 indicates an outlier)

```{r}
crime_lm <- lm(expend~bad+crime+lawyers+employ+pop, data=crime_df)
cooks.distance(crime_lm)[cooks.distance(crime_lm) > 1]
```
```{r, echo=FALSE}
plot(cooks.distance(crime_lm), type='b', ylab="Cook's distance", main = "Cook's distance for expensecrime.txt")
```

We can see that indices of 5, 8, 35 and 44 are outliers, which we can remove:

```{r}
crime_df_upd <- crime_df[-c(5,8,35,44),]
```

To further investigate collinearity, we can examine the correlations between all the explanatory variables, which confirms strong correlations between *bad*, *lawyers*, *employ* and *pop*.

```{r}
round(cor(crime_df[, c(exp_vars)]), 2)
```
<<<<<<<< IS VIF NECCESSARY?  >>>>>>>>

To resolve the problem of collinearity, we can iteratively remove variables based on their VIF-values as follows:

```{r, include=FALSE}
library(car)
```

Full model:

```{r}
vif(lm(expend~bad+crime+lawyers+employ+pop, data=crime_df))
```

Remove *employ*:

```{r}
vif(lm(expend~bad+crime+lawyers+pop, data=crime_df_upd))
```

Remove *pop*:

```{r}
vif_lm = lm(expend~bad+crime+lawyers, data=crime_df_upd)
vif(vif_lm)
```

```{r}
summary(vif_lm)
```
In the resulting model, all the explanatory variables are significant.

<<<<<<<< SHOULD WE SHOW PLOT AGAIN?? >>>>>>>>

Therefore, after removing the influence points and collinear explanatory variables, the adjusted scatter plot appears as follows. We will work with this adjusted data for the remainder of this question.

```{r}
pairs(crime_df_upd[, c(response, "bad", "crime", "lawyers")])
```

**b)** 

```{r, include=FALSE}
print("Step 1")

print("bad")
summary(lm(expend~bad, data=crime_df_upd))

print("crime")
summary(lm(expend~crime, data=crime_df_upd))

print("lawyers")
summary(lm(expend~lawyers, data=crime_df_upd))

print("employ")
summary(lm(expend~employ, data=crime_df_upd)) # YES

print("pop")
summary(lm(expend~pop, data=crime_df_upd)) 
```

```{r, include=FALSE}
print("Step 2")

print("bad")
summary(lm(expend~employ+bad, data=crime_df_upd))

print("crime")
summary(lm(expend~employ+crime, data=crime_df_upd)) # YES

print("lawyers")
summary(lm(expend~employ+lawyers, data=crime_df_upd))

print("pop")
summary(lm(expend~employ+pop, data=crime_df_upd))
```

```{r, include=FALSE}
print("Step 3")

print("bad")
summary(lm(expend~employ+crime+bad, data=crime_df_upd))

print("lawyers")
summary(lm(expend~employ+crime+lawyers, data=crime_df_upd))

print("pop")
summary(lm(expend~employ+crime+pop, data=crime_df_upd)) # YES
```

```{r, include=FALSE}
print("Step 4")

print("bad")
summary(lm(expend~employ+crime+pop+bad, data=crime_df_upd))

print("lawyers")
summary(lm(expend~employ+crime+pop+lawyers, data=crime_df_upd))

# None significant!
```

The step-up process was carried out. The variables added in order were *employ*, *crime* and *pop*, after which no further added variables had significant p-values. Hence the final model is as follows:

```{r}
step_up_lm <- lm(expend~employ+crime+pop, data=crime_df_upd)
summary(step_up_lm)
```

Final model: expend = -247 + 0.0209\*employ + 0.0543\*crime + 0.0714\*pop $\pm$ error, with $R^2 = 0.974$.

We see that the step-up method naturally removes collinearity and produced a better model than was arrived upon using VIF in (a), which had an R-squared value of 0.957.

Finally, we check the model assumptions, which can be accepted based on the following plots:

```{r, echo=FALSE}
par(mfrow=c(1,2))

qqnorm(residuals(step_up_lm))
plot(fitted(step_up_lm), residuals(step_up_lm))
```

**c)** 

Using the step-up model found in (b), the 95% prediction interval for *expend* is given by:
```{r}
new_data <- data.frame(bad=50, crime=5000, lawyers=5000, employ=5000, pop=5000)
predict(step_up_lm, new_data, interval="prediction", level=0.95)
```

We can improve this interval (make it more narrow) by considering the **confidence interval**, which does not take into account the error.

```{r}
predict(step_up_lm, new_data, interval="confidence", level=0.95)
```

**d)** 

We can apply the lasso method as follows:
```{r, include=FALSE}
# install.packages("glmnet", repos = "https://cran.us.r-project.org")
library(glmnet)
```

```{r}
x <- as.matrix(crime_df_upd[, exp_vars])
y <- as.matrix(crime_df_upd[, c(response)])

# train-test splitting
train <- (sample(1:nrow(x), 0.67*nrow(x))) # train by using 2/3 of the data
x.train <- x[train,]; y.train <- y[train]
x.test <- x[-train,]; y.test <- y[-train]

# fitting the model
lasso.mod <- glmnet(x.train, y.train, alpha=1)
cv.lasso <- cv.glmnet(x.train,y.train,alpha=1,type.measure='mse')
```

```{r}
plot(lasso.mod, label=T, xvar="lambda")  # have a look at the lasso path
```

```{r}
plot(cv.lasso) # the best lambda by cross-validation
```

```{r}
(lambda.min <- cv.lasso$lambda.min)
(lambda.1se <- cv.lasso$lambda.1se)
```

```{r}
# https://glmnet.stanford.edu/articles/glmnet.html#assessing-models-on-test-data-1
assess.glmnet(lasso.mod, newx = x.test, newy = y.test, s=cv.lasso$lambda.1se)
```

Looking at lambda min
```{r}
coef(lasso.mod, s=cv.lasso$lambda.min) # beta’s for the best lambda
y.pred <- predict(lasso.mod, s=lambda.min, newx=x.test) # predict for test
mse.lasso <- mean((y.test - y.pred)^2); mse.lasso # mse for the predicted test rows
```

Looking at lambda 1se (the one we should use I think?)
```{r}
coef(lasso.mod, s=cv.lasso$lambda.1se) # beta’s for lambda.1se
y.pred <- predict(lasso.mod, s=lambda.1se, newx=x.test) # predict for test
mse.lasso <- mean((y.test - y.pred)^2); mse.lasso # mse for the predicted test rows
```
Compare to step-up model in (b).
```{r}
new_data <- data.frame(x.test)
y.pred <- predict(step_up_lm, new_data, interval="confidence", level=0.95)
mse.step_up <- mean((y.test - y.pred)^2); mse.step_up # mse for the predicted test rows
```

Step-up model is better? Is this the right way to compare?

```{r}
cv.lasso
```


## Exercise 3

```{r, include=FALSE}
# Read data
titanic_df <- as.data.frame(read.table("data/titanic.txt", header=TRUE))
```

```{r}
head(titanic_df)
```

```{r}
plot(titanic_df)
```


**a)** 

```{r}
titanic_df$PClass <- as.factor(titanic_df$PClass)
titanic_df$Sex <- as.factor(titanic_df$Sex)
summary(titanic_df)
```

```{r}
tot_comb <- xtabs(~PClass+Sex, data=titanic_df)
tot_comb
```
```{r}
tot_comb.surv <- xtabs(Survived~PClass+Sex, data=titanic_df)
round(tot_comb.surv/tot_comb, 2)
```

```{r}
par(mfrow=c(1, 2))
hist(titanic_df$Age)
hist(titanic_df$Age[titanic_df$Survived == 1], ylim =c(0, 140))
```

```{r}
tot_age <- xtabs(~Age, data=titanic_df)
barplot(xtabs(Survived~Age, data=titanic_df)/tot_age)
```

```{r}
boxplot(Age ~ Sex + PClass, data=titanic_df, col = c("#FFE0B2", "#F57C00")) 
```

```{r}
titanic_df_upd <- na.omit(titanic_df)
titanic_df_upd$PClass <- as.factor(titanic_df_upd$PClass)
titanic_df_upd$Sex <- as.factor(titanic_df_upd$Sex)
# head(titanic_df_upd)

base_lm <- glm(Survived ~ Age+PClass+Sex, data = titanic_df_upd, family = binomial)
```

```{r}
summary(base_lm)
```

```{r}
exp(coef(base_lm))
```

TODO: add discussion of odds from the paper

**b)** 

```{r}
anova(glm(Survived ~ Age*PClass, data = titanic_df_upd, family = binomial), test="Chisq")
```

```{r}
anova(glm(Survived ~ Age*Sex, data = titanic_df_upd, family = binomial), test="Chisq")
```
Therefore we decided to keep following model as Age:Sex intersection is significant.

```{r}
final_lm <- glm(Survived ~ PClass+Age*Sex, data = titanic_df_upd, family = binomial)
anova(final_lm, test="Chisq")
```

```{r}
newdata <- data.frame(Age=c(55, 55, 55, 55, 55, 55), PClass=c("1st", "1st", "2nd", "2nd", "3rd", "3rd"), Sex=c("female", "male", "female", "male", "female", "male"))
predict(final_lm, newdata, type="response")
```

For "female" all the probs > 0.5 and for the "male" probs are < 0.5.

**c)** 
Use confusion matrix, log likelihood as quality measures

**d)** 

```{r}
table(titanic_df_upd$PClass, titanic_df_upd$Sex)
```
```{r}
chisq.test(x=titanic_df_upd$Survived, y=titanic_df_upd$Sex)
```
For 2x2 tables we can obtain exact p-value using the Fisher test.

```{r}
fisher.test(x=titanic_df_upd$Survived, y=titanic_df_upd$Sex)
```


```{r}
chisq.test(x=titanic_df_upd$Survived, y=titanic_df_upd$PClass)
```
We reject null hypothesis, meaning that rows and cols are actually dependent: Sex and PClass have influence on Survived variable.

**e)** 

TODO: comparison btw c) and d) ?

contingency table tells us only about the presence of effect and doesn't provide some quantitative characteristics

## Exercise 4

```{r, include=FALSE}
# Read data
coups_df <- as.data.frame(read.table("data/coups.txt", header=TRUE))
```

```{r}
head(coups_df)
```

```{r}
# coups_df$pollib <- as.factor(coups_df$pollib)
# coups_df$numregim <- as.factor(coups_df$numregim)
summary(coups_df)
```

```{r}
hist(coups_df$miltcoup)
```

```{r}
plot(coups_df)
```


**a)** 
```{r}
poison_glm <- glm(miltcoup ~ oligarchy + pollib + parties + pctvote + popn + size + numelec + numregim, data = coups_df, family = poisson)
summary(poison_glm)
```

<!-- ```{r} -->
<!-- drop1(poison_glm, test="Chisq") -->
<!-- ``` -->

Through summary(drop1)we can find the variables that are significant in predicting number of successful military coups: oligarchy, pollib, parties.

**b)** 

```{r}
summary(glm(miltcoup ~ oligarchy + pollib + parties + pctvote + popn + size + numelec, data = coups_df, family = poisson), test="Chisq")
```

```{r}
summary(glm(miltcoup ~ oligarchy + pollib + parties + pctvote + popn + size, data = coups_df, family = poisson), test="Chisq")
```

```{r}
summary(glm(miltcoup ~ oligarchy + pollib + parties + pctvote + popn, data = coups_df), test="Chisq")
```

```{r}
summary(glm(miltcoup ~ oligarchy + pollib + parties + popn, data = coups_df), test="Chisq")
```

```{r}
final_plm <- glm(miltcoup ~ oligarchy + parties + pollib, data = coups_df, family = poisson)
summary(final_plm, test="Chisq")
```

After step-down approach there are oligarchy, parties and pollib left. (For treating vars as factors only oligarchy left)
In comparison with a) all the same factors are significant.

**c)** 

```{r}
coups_df$pollib <- as.factor(coups_df$pollib)
coups_df$numregim <- as.factor(coups_df$numregim)
```

```{r}
mean(coups_df$oligarchy); mean(coups_df$parties)
```


```{r}
newdata <- data.frame(pollib=c(0, 1, 2), oligarchy=c(5.22, 5.22, 5.22), parties=c(17.1, 17.1, 17.1))
predict(final_plm, newdata, type="response")
```

Our model is predicting there will be roughly 3 successful coups for pollib=0, roughly 2 successful coups for pollib=1 and 1 successful coup for pollib=2.
