---
title: "Assignment 1"
author: "Alexia Salomons, Nathan Maxwell Jones, Yauheniya Makarevich, group 71"
date: "27 February 2023"
output: pdf_document
fontsize: 11pt
highlight: tango
---

```{r, echo=FALSE}
options(digits=3)
```


## Exercise 1. 
The data set birthweight.txt contains the birthweights (in grams) of 188 newborn babies. Denote the underlying mean birthweight by $\mu$.

```{r}
birthweight <- readLines("data/birthweight.txt")
birthweight <- as.double(birthweight[2:length(birthweight)])
birthweight
```
```{r}
length(birthweight)
```

```{r}
birthweight_mean <- mean(birthweight)
birthweight_mean
```

**a)** Check normality of the data. Assuming normality (irrespective of your conclusion about normality), construct a bounded 96%-CI for $\mu$. Evaluate the sample size needed to provide that the length of the 96%-CI is at most 100. Compute a bootstrap 96%-CI for $\mu$ and compare it to the above CI.


```{r}
qqnorm(y = birthweight)
```

```{r}
hist(birthweight)
# add density line
# lines(density(birthweight), col="blue",lwd=2)
```

```{r}
shapiro.test(birthweight)
# H0 - normal distribution, H1 - not normal
```
NORMAL DISTRIBUTION!

Let's go for CI-96%:

```{r}
t.test(birthweight, conf.level = 0.96)
```
```{r}
B <- 1000
alpha <- 0.04
T_star <- numeric(B)

for(i in 1:B) {
  X_star <- sample(birthweight, replace = TRUE)
  T_star[i] <- mean(X_star)
}

T_star_q2 <- quantile(T_star, alpha/2)
T_star_q98 <- quantile(T_star, 1 - alpha/2)

c(2*birthweight_mean - T_star_q98, 2*birthweight_mean - T_star_q2)
```
```{r}
sum(T_star<T_star_q2)
```

<!-- #TODO: FIGURE OUT SAMPLE SIZE FOR HAVING CI INTERVAL LENGTH + 100 -->
<!-- 828 babies to get the CI -->

**b)**  An expert claims that the mean birthweight is bigger than 2800 gram. Verify this claim by using a relevant t-test, explain the meaning of the CI in the R-output for this test. Also propose and perform a suitable sign tests for this problem.

```{r}
t.test(birthweight, alternative = "greater", mu=2800)
```
We reject H0(p=0.01337), so H1 is true and mean of the sample is bigger than 2800. 
CI is infinite on right side, since the test is one-sided.


Binom test

H0: mean <= 2800,
H1: mean > 2800.

```{r}
greater_weight <- as.integer(birthweight > 2800)
binom.test(sum(greater_weight), length(greater_weight), p=0.5, alt="g")
```
We reject H0(p=0.03868), so H1 is true and mean of the sample is bigger than 2800. 

Both test confirmed the hypothesis that mean of the sample is bigger than 2800.

**c)** Propose a way to compute the powers of the t-test and sing test from b) at some $\mu$ > 2800, comment.
```{r}


```

**d)**  Let $p$ be the probability that birthweight of a newborn baby is less than 2600 gram. Using asymptotic normality, the expert computed the left end $\hat{p}=0.25$ of the confidence interval $[\hat{p_l}, \hat{p_r}]$ for $p$. Recover the whole confidence interval and its confidence level.
```{r}

```

**e)** The expert also reports that there were 34 male and 28 female babies among 62 who weighted less than 2600 gram, and 61 male and 65 female babies among the remaining 126 babies. The expert claims that the mean weight is different for male and female babies. Verify this claim by an appropriate test.


success: w > 2600
```{r}
prop.test(c(61, 65), c(95, 93))
```
We accept H0: p1-p2=0, where p1, p2 - proportions of the success in population.

## Exercise 2
A study tested whether cholesterol was reduced after using a certain brand of margarine as part of a low fat low cholesterol diet. The data set cholesterol.txt contains information on 18 people using margarine to reduce cholesterol: columns Before and After8weeks contain the cholesterol level (mmol/L) respectively before the diet and after 8 weeks on the diet.

```{r}
df <- as.data.frame(read.table("data/cholesterol.txt", header=TRUE))
head(df)
```


**a)** Make some relevant plots of this data set, comment on normality. Are there any inconsistencies in the data? Investigate whether the columns Before and After8weeks are correlated.
```{r}
diffs <- df[, 1] - df[, 2]
diffs
qqnorm(diffs)
```

```{r}
hist(diffs)
```
```{r}
shapiro.test(diffs)
```
Differences are normally distributed.

```{r}
shapiro.test(df[, 1])
shapiro.test(df[, 2])
```
```{r}
cor.test(df[, 1], df[, 2], method="pearson")
```

```{r}
# Create a first line
plot(1:length(df[, 1]), df[, 1], type = "b", pch=19, col = "red", xlab = "individual", ylab = "cholesterol")
lines(1:length(df[, 2]), df[, 2], pch=18, col = "blue", type = "b", lty=2)
legend("topleft", legend=c("Before", "After"), col=c("red", "blue"), lty = 1:2, cex=0.8)
```

**b)** Apply two relevant tests (cf. Lectures 2, 3) to verify whether the diet with low fat margarine has an effect (argue whether the data are paired or not). Is a permutation test applicable?

Data is paired since it is two different measurements of the same person and two samples are correlated.
Relevant test:

1. T-test paired test
```{r}
t.test(df[, 1], df[, 2], paired=2)
```
-> based on p-value we reject null-hypothesis that samples have the same mean. there is a difference between these two samples.

2. Permutation test - it is applicable because we are only testing for a difference between mean, not how they relate to each other.
```{r}
diff_mean <- function(x, y) {
  return(mean(x-y))
}

# original dataframe
stats <- diff_mean(df[, 1], df[, 2])
stats

B <- 1000
t_star <- numeric(B)

for (i in 1:B) {
  diff_star <- t(apply(cbind(df[, 1], df[, 2]), 1, sample))
  t_star[i] <- diff_mean(diff_star[, 1], diff_star[, 2])
}

hist(t_star)
# plot(rep(stats, 2), c(0, 50), col="red", lwd=2)
lines(rep(stats, 2), c(0, 50), col="red", lwd=2)
```
```{r}
# calculating p-value
pl <- sum(t_star < stats) / B
pr <- sum(t_star > stats) / B

p <- 2*min(pl, pr)
p
```

**c)**
$\mu = (\theta + 3) / 2, \theta > 3$
```{r}

mu <- mean(df[, 2])
mu # bar{x}

s <- sd(df[, 2])
s

theta_hat <- 2*mu - 3
theta_hat

alpha <- 0.05

n <- length(df[, 2])
t_alpha <- qt(1 - alpha/2, df=n)
t_alpha

theta_l <- theta_hat - t_alpha*s/sqrt(n)
theta_r <- theta_hat + t_alpha*s/sqrt(n)
c("[", theta_l,",", theta_r, "]")
```
We can improve the CI by having more individuals in the samples.

**d)** 

```{r}
t <- max(df[, 2])
t

n <- length(df[, 2])
n

for (theta in 3:12) {
  B <- 1000
  t_star <- numeric(B)
  
  for (i in 1:B) {
    x_star <- runif(n, min = 3, max = theta)
    t_star[i] <- max(x_star)
  }
  
  pl <- sum(t_star < t)/B
  pr <- sum(t_star > t)/B
  
  p <- 2* min(pl, pr)
  print(paste("Theta =", theta, ", ", p))
}
```
**e)**
Medium and proportion tests
```{r}
less_chol <- as.integer(df[, 2] < 6)
binom.test(sum(less_chol), length(less_chol), p=0.5, alt="g")
```
```{r}
less_chol <- as.integer(df[, 2] < 4.5)
binom.test(sum(less_chol),length(less_chol),p=0.25, alt="l")
```
## Exercise 3

```{r}
df <- as.data.frame(read.table("data/diet.txt", header=TRUE))
df["weight.lost"] <- df["preweight"] - df["weight6weeks"]
head(df)
```
**a)**
```{r}
# Create a first line
plot(1:length(df[,5]), df[,5], type = "b", pch=19, col = "red", xlab = "individual", ylab = "weight (kg)")
lines(1:length(df[,7]), df[,7], pch=18, col = "blue", type = "b", lty=2)
legend("topleft", legend=c("Before", "After"), col=c("red", "blue"), lty = 1:2, cex=0.8)
```
```{r}
t.test(df[,5], df[,7], paired=TRUE)
```
Therefore diet does have an effect on weight loss.

Now check assumptions (normality)
```{r}
hist(df[,8])
```
```{r}
qqnorm(df[,8])
```
```{r}
shapiro.test(df[,8])
```
Data is normal :)

**b)**
Fromat data
```{r}
df$diet <- as.factor(df$diet)
dietaov=lm(weight.lost~diet,data=df)
anova(dietaov)
summary(dietaov)
```
The best diet is number 3. 
```{r}
# Checking assumptions
qqnorm(residuals(dietaov))
plot(fitted(dietaov), residuals(dietaov))
```

```{r}
kruskal.test(df$weight.lost, df$diet)
```
This supports the ANOVA result.

**c)**

```{r}
df$gender <- as.factor(df$gender)
dietgenderaov <- lm(weight.lost~gender*diet,data=df)
anova(dietgenderaov)
```

```{r}
summary(dietgenderaov)
```

```{r}
par(mfrow=c(1, 2))
interaction.plot(df$gender, df$diet, df$weight.lost)
interaction.plot(df$diet, df$gender, df$weight.lost)
```

Assumption: diet depends on gender, we can see that effect of diet varies inside women.

```{r}
genderaov <- lm(weight.lost~gender,data=df)
anova(genderaov)
summary(genderaov)
```

```{r}
# Checking assumptions
par(mfrow=c(1, 2))
qqnorm(residuals(dietgenderaov))
plot(fitted(dietgenderaov), residuals(dietgenderaov))
```
Residuals do not look like something that is normally distributed, which violates our assumptions about normality and makes 

**e)**
We prefer b) as c) looks irrelevant for the weight loss. 
```{r}
print(paste('Diet 1:', dietaov$coefficients[1]))
print(paste('Diet 2:', dietaov$coefficients[1] + dietaov$coefficients[2]))
print(paste('Diet 3:', dietaov$coefficients[1] + dietaov$coefficients[3]))
```

## Exercise 4

**a)**
```{r}
require("MASS")
```

```{r}
B <- 6
P <- 4
T <- 3

process <- c()
for (i in 1:B) {
  block <- c()
  for (tr in 1:T) {
    block <- cbind(block, as.numeric(sample(1:P) > 2))
  }
  process <- rbind(process, block)
}
process
```

**b)**
```{r}
interaction.plot(npk$block, npk$N, npk$yield)
```

N has effect on yield
We should take block into accountance since different plots in blocks have different combinations of other fertilizers ???????

**c)**
```{r}
# We do plus as we don't care about interactions ---> actually I think we do
npk2anova <- lm(yield~block*N, data=npk)
anova(npk2anova)
```

```{r}
summary(npk2anova)
```

Changes in blocks are not significant so we can consider that block variable doesn't affect

Friedman test:
- we have two observation for each combination
- we can't use it

**d)**
```{r}
npklm1 <- lm(yield~P + K + block*N, data=npk)
npklm2 <- lm(yield~N + K + block*P, data=npk)
npklm3 <- lm(yield~N + P + block*K, data=npk)

anova(npklm1)
anova(npklm2)
anova(npklm3)
```

**e)**

```{r}
library(lme4)
npklmer <- lmer(yield~N+(1|block), REML=FALSE, data=npk)
npklmer1 <- lmer(yield~(1|block), REML=FALSE, data=npk)
anova(npklmer1, npklmer)
```

Nitrogen has a significant effect. 